{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals for this section\n",
    "1. Use Julia high-performance IO packages to store the results of our simulations\n",
    "2. Learn more about Julia's parallel computing capabilities with respect to partitioning work, storing pre-computed results, etc.\n",
    "3. Branch our into the wild, wild world of condensed matter physics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Want a way to save/load our data.\n",
    "We can use [HDF5](https://github.com/JuliaIO/HDF5.jl) for maximum portability or [JLD](https://github.com/JuliaIO/JLD.jl) if we are comfortable staying in the Julia ecosystem. Or, attend Simon's talk about [JLD2](https://github.com/simonster/JLD2.jl) for more information about cutting-edge IO in Julia! For now, we will stick with HDF5 for portability.\n",
    "\n",
    "Some patterns we could use:\n",
    "\n",
    "1. Have every worker send their data to the driver, and have it write one file\n",
    "2. Have each worker write its own data file, then collate them at the end using some script\n",
    "3. Have a group of workers dedicated to collecting data and collating\n",
    "\n",
    "3 is intermediate between 1 and 2. Each one has advantages and disadvantages. 3 will let us show off some cool Julia features like `WorkerPool` and it's also the most difficult to get right, so let's do that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "addprocs(6)\n",
    "\n",
    "IOPool = WorkerPool([2; 3]) # worker \"1\" is the driver worker\n",
    "ComputePool = CachingPool([4; 5; 6; 7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make `ComputePool` a [`CachingPool`](https://docs.julialang.org/en/latest/stdlib/parallel/#Base.Distributed.CachingPool) so that it can store information about the Hamiltonian between timesteps. Hopefully this will cut down on our runtimes! Now we want to:\n",
    "\n",
    "1) Have `ComputePool` work on our time evolution function from last time (we'll modify our call to `pmap` to do this)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function timeSeriesParallel(psi, H, start, step, stop; worker_pool::WorkerPool=default_worker_pool())\n",
    "    times = linspace(start, step, stop)\n",
    "    pmap(worker_pool, (t,)->timeEvolve(psi, H, t), times)\n",
    "end\n",
    "\n",
    "addprocs(6)\n",
    "psi, H = get_groundstate(10, 1.0)\n",
    "t_vecs = timeSeriesParallel(psi, H, 0.0, 0.1, 10.0, worker_pool = ComputePool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) For each eigenvector we get back from `ComputePool`, feed it to `IOPool` to write to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@everywhere function WriteToDisk(vector, index, file_name_root)\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Have the driver node make a plot for us in the meantime (we already have code to do this!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we are ready to upload our data to Git LFS and head out to arXiv!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going Forward\n",
    "\n",
    "Hopefully everyone got to learn some physics and some Julia (or at least how you can use Julia to do physics!). Some suggestions of next steps to try:\n",
    "- any of the exercises you didn't manage to get through\n",
    "- add disorder - make the $\\Delta$ in the $XXZ$ model or $h$ in the transverse field Ising model vary by site $i$. Note that you'll probably need to *disorder average* - generate many (200+) Hamiltonians with different randomness samples and average over their results\n",
    "- use your quench code to visualize [spin echo](https://en.wikipedia.org/wiki/Spin_echo) at the edge of the chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.0-rc1",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
